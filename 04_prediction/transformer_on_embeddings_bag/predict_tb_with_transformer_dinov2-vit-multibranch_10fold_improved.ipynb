{
 "cells": [
  {
   "cell_type": "raw",
   "id": "77f82339-baf2-44e2-b722-532e01136465",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install hydra-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46db1e-b647-45bd-a04c-c01a3b3ec209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import auc as calc_auc, precision_recall_curve, average_precision_score\n",
    "import random\n",
    "import glob\n",
    "import ngsci\n",
    "import hydra\n",
    "import h5py\n",
    "sys.path.append(\"../../../03_training/transformer_on_embeddings_bag/\")\n",
    "from transformer_model_cls_multi_branch import MULTI_BRANCH_TRANSFORMER_CLASSIFIER\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from omegaconf import DictConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34581f7-47db-4c86-ab61-a2be353af0b5",
   "metadata": {},
   "source": [
    "## LOAD CORRESPONDING SAVED CONFIG FILE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1baf17d-f90b-41bf-909d-ef6ab8bd152d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preproc_conf = OmegaConf.load(\"/home/ngsci/project/tuberculosis_detection/conf/preproc.yaml\")\n",
    "train_conf   = OmegaConf.load(\"/home/ngsci/project/tuberculosis_detection/conf/train.yaml\")\n",
    "config_level_0 = \"transformer_on_embeddings_bag\"\n",
    "\n",
    "preproc_config_level_1_branch_1 = \"uni_224_224_patches\"\n",
    "preproc_config_level_1_branch_2 = \"dinov2-vit-large_224_224_patches\"\n",
    "train_config_level_1_branch_1   = \"uni_224_224_patches_cls\"\n",
    "train_config_level_1_branch_2   = \"dinov2-vit-large_224_224_patches_cls\"\n",
    "train_config_level_1            = \"dinov2-vit-large_and_uni_224_224_patches_cls\"\n",
    "\n",
    "\n",
    "conf_preproc_branch_1 = preproc_conf[config_level_0][preproc_config_level_1_branch_1]\n",
    "conf_preproc_branch_2 = preproc_conf[config_level_0][preproc_config_level_1_branch_2]\n",
    "\n",
    "conf_train_branch_1 = train_conf[config_level_0][train_config_level_1_branch_1]\n",
    "conf_train_branch_2 = train_conf[config_level_0][train_config_level_1_branch_2]\n",
    "\n",
    "\n",
    "conf_train = OmegaConf.load(\"/home/ngsci/project/tuberculosis_detection/03_training/transformer_on_embeddings_bag/dinov2-vit-large_and_uni_224_224_patches_cls/runs/run_1/conf_train.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1be0f-bfce-4106-8fee-1925705ee1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda:0' \n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14017e8-372f-4c66-8dc5-8ba4c0fe72f6",
   "metadata": {},
   "source": [
    "## Load models from CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9467adb-b266-4500-a361-78f8a3704871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = conf_train.results_dir\n",
    "results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff6eb0-8524-4af7-a5fb-35017520272b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoints_dir_cv_0 = f'{results_dir}cv_0/'\n",
    "checkpoints_dir_cv_1 = f'{results_dir}cv_1/'\n",
    "checkpoints_dir_cv_2 = f'{results_dir}cv_2/'\n",
    "checkpoints_dir_cv_3 = f'{results_dir}cv_3/'\n",
    "checkpoints_dir_cv_4 = f'{results_dir}cv_4/'\n",
    "checkpoints_dir_cv_5 = f'{results_dir}cv_5/'\n",
    "checkpoints_dir_cv_6 = f'{results_dir}cv_6/'\n",
    "checkpoints_dir_cv_7 = f'{results_dir}cv_7/'\n",
    "checkpoints_dir_cv_8 = f'{results_dir}cv_8/'\n",
    "checkpoints_dir_cv_9 = f'{results_dir}cv_9/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac6753-9946-4a9b-86af-a1dcbe8dab8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_names_all_cv = np.array([ np.array( sorted(  glob.glob( os.path.join(eval(f\"checkpoints_dir_cv_{i}\"), \"*.pt\"))   )) for i in range(10) ], dtype=object)\n",
    "file_names_all_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052cd3bb-36c8-4b83-b1f2-73ca6172aa55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_names_all_cv[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab60867-5ee7-416b-a131-9ce3aee4e510",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d04e15-b048-4cd2-a6ec-19d1618b92e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_bag_input_path = conf_preproc_branch_1.emb_dir\n",
    "\n",
    "tb_df_local_test = pd.read_csv(conf_preproc_branch_1[\"cv_split_dir\"] +'test_split_stratified.csv')\n",
    "tb_df_local_test.sort_values('image', inplace=True)\n",
    "embeddings_bag_input_files_local_test = np.array( sorted([ embeddings_bag_input_path + os.path.basename(i).replace(\".jpg\", \".h5\") for i in tb_df_local_test.file_path.values ]) )\n",
    "\n",
    "embeddings_bag_input_files_local_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7badd80-64c4-4a25-966a-b7c0fa614766",
   "metadata": {},
   "source": [
    "## Look for best models based on AUC or VAL LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea2450-ca1f-4d5d-aa7e-06eedc0e4ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a744349-ac47-47b5-92c0-2d4b27ceb53f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_val_auc = []\n",
    "\n",
    "for i in range(file_names_all_cv.shape[0]):\n",
    "    select = 10\n",
    "    max_auc_sort_index = np.argsort([float(os.path.basename(item).split('_')[5]) for item in file_names_all_cv[i]])[::-1]\n",
    "    \n",
    "    for m in range(select):\n",
    "        max_auc_model = file_names_all_cv[i][max_auc_sort_index[m]]\n",
    "        best_models_on_val_auc.append(max_auc_model)\n",
    "\n",
    "best_models_on_val_auc = np.array(best_models_on_val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d73193-ad50-4306-8e1e-7ca56b8c0cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_val_auc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e51d5-2a43-453f-a4ea-609c51e2c233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_val_auc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5745d6-15eb-48d7-a244-79c911492de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"ROC AUC of selected models: \", np.mean([float(e.split('_auc_')[1].split('_')[0]) for e in best_models_on_val_auc]))\n",
    "print(\"PR AUC of selected models: \", np.mean([float(e.split('_prauc_')[1].split('_')[0]) for e in best_models_on_val_auc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921b5d37-2c60-4aa1-affe-8d108a14a4e5",
   "metadata": {},
   "source": [
    "#### PR AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7512e60-d2fc-4e4c-a502-ee40ed999548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_prauc = []\n",
    "\n",
    "for i in range(file_names_all_cv.shape[0]):\n",
    "    select = 10\n",
    "    max_prauc_sort_index = np.argsort([float(os.path.basename(item).split('_')[7]) for item in file_names_all_cv[i]])[::-1]\n",
    "    \n",
    "    for m in range(select):\n",
    "        max_prauc_model = file_names_all_cv[i][max_prauc_sort_index[m]]\n",
    "        best_models_on_prauc.append(max_prauc_model)\n",
    "\n",
    "best_models_on_prauc = np.array(best_models_on_prauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8f56d-a4b4-4e3a-8c93-ce9ed52e3554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_prauc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cd830-fbd3-41ea-8cf9-20933dd41863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_prauc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658de2f6-99a9-45f1-811c-2f234019d741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"ROC AUC of selected models: \", np.mean([float(e.split('_auc_')[1].split('_')[0]) for e in best_models_on_prauc]))\n",
    "print(\"PR AUC of selected models: \", np.mean([float(e.split('_prauc_')[1].split('_')[0]) for e in best_models_on_prauc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20638b68-1085-4c9a-83e3-7ed7a58062ff",
   "metadata": {},
   "source": [
    "## Predict with model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232e952-6aed-4df0-b6dd-39d432c126a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_roc(y_true, y_pred):\n",
    "    if y_pred.shape != y_true.shape:\n",
    "        # try to one-hot encode y_true\n",
    "        y_true = F.one_hot(torch.from_numpy(y_true).to(torch.int64), 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    auc_all = []\n",
    "    for class_ind in range(y_pred.shape[-1]):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, class_ind], y_pred[:, class_ind])\n",
    "        auc = roc_auc_score(y_true[:, class_ind], y_pred[:, class_ind])\n",
    "        auc_all.append(auc)\n",
    "        plt.plot(fpr, tpr, '-', label='AUC : %.3f, label : %d' % (auc, class_ind))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44766d01-68c8-4579-9dcd-3e3d0c6701bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_merged_h5_file(filename):\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        coords = f['coords'][()]\n",
    "        features = f['features'][()]\n",
    "        tb_positive = f['tb_positive'][()]\n",
    "        \n",
    "        return coords, features, tb_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0252194-290e-4552-bb87-e547ad1a87a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_merged_h5_file_indices(filename, sample_indices):\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        coords = f['coords'][sample_indices]\n",
    "        features = f['features'][sample_indices]\n",
    "        tb_positive = f['tb_positive'][sample_indices]\n",
    "        \n",
    "        return coords, features, tb_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a38de0-22c0-426c-a1b7-0f882391eb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class h5_Dataset(Dataset):\n",
    "    def __init__(self, emb_file_in_memory, transform=None):\n",
    "        self.transform = transform\n",
    "        self.emb_file_in_memory = emb_file_in_memory                                \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.emb_file_in_memory.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_data = self.emb_file_in_memory[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        \n",
    "        return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ae5e7-4d6c-4a6e-be76-30aeec7931fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8baed7-d121-40ae-82a3-71e5b97d7644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_with_one_model(model, data_loader_1, data_loader_2):\n",
    "    \n",
    "    preds_all = []\n",
    "    labels_all = []\n",
    "    \n",
    "    for (data1, data2) in zip(data_loader_1, data_loader_2):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            data1 = data1.to(DEVICE, dtype=torch.float32, non_blocking=True)\n",
    "            data2 = data2.to(DEVICE, dtype=torch.float32, non_blocking=True)\n",
    "                           \n",
    "            _, preds, label, _, _ = model(data1, data2)\n",
    "\n",
    "        preds_all.append(preds.cpu().detach().numpy()[:,:2])\n",
    "        labels_all.append(label.cpu().numpy())\n",
    "        \n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    labels_all = np.concatenate(labels_all)\n",
    "    \n",
    "    return preds_all, labels_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99f308-29de-492e-b663-ec55609db4f8",
   "metadata": {},
   "source": [
    "### Select best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78930f9d-5dd7-46ba-9d01-bd84ebe9925e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_selected_metric = best_models_on_prauc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5a896a7-f095-473c-bff0-f57c6782a848",
   "metadata": {
    "tags": []
   },
   "source": [
    "best_models_on_selected_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb3ec8-4d32-4339-a7f2-127e1aceefc4",
   "metadata": {},
   "source": [
    "### Local test set - multiple branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d943d-2c50-4d0b-9216-41d8a17a163b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOAD MERGED H5 IN MEMORY\n",
    "print(\"Loading merged h5 local test file into memory - branch 1...\")\n",
    "\n",
    "test_df = pd.read_csv(f'{conf_preproc_branch_1[\"cv_split_dir_10fold\"]}test_split_stratified.csv')\n",
    "sample_indices_test = np.array([ int(os.path.basename(f).replace(\".jpg\",\"\").replace(\"tb\",\"\"))-1 for f in test_df[\"file_path\"] ])\n",
    "\n",
    "coords_h5_1, features_h5_1, tb_positive_h5_1 = load_merged_h5_file_indices(conf_preproc_branch_1[\"emb_h5\"], sample_indices_test)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(features_h5_1.shape)\n",
    "\n",
    "\n",
    "print(\"\\nLoading merged h5 local test file into memory - branch 2...\")\n",
    "\n",
    "test_df = pd.read_csv(f'{conf_preproc_branch_1[\"cv_split_dir_10fold\"]}test_split_stratified.csv')\n",
    "sample_indices_test = np.array([ int(os.path.basename(f).replace(\".jpg\",\"\").replace(\"tb\",\"\"))-1 for f in test_df[\"file_path\"] ])\n",
    "\n",
    "coords_h5_2, features_h5_2, tb_positive_h5_2 = load_merged_h5_file_indices(conf_preproc_branch_2[\"emb_h5\"], sample_indices_test)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(features_h5_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8bace-ab39-4ee6-bd02-7e7b079e2d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_models = best_models_on_selected_metric.shape[0]\n",
    "\n",
    "preds_ensemble_local_test = np.zeros((best_models_on_selected_metric.shape[0], embeddings_bag_input_files_local_test.shape[0], 2))\n",
    "labels_ensmble_local_test = np.zeros((best_models_on_selected_metric.shape[0], embeddings_bag_input_files_local_test.shape[0], 1))\n",
    "\n",
    "# DEFINE DATALOADERS\n",
    "test_df = pd.read_csv(f'{conf_preproc_branch_1[\"cv_split_dir_10fold\"]}test_split_stratified.csv')\n",
    "test_dataset_1 = h5_Dataset(features_h5_1)\n",
    "test_dataset_loader_1 = torch.utils.data.DataLoader(test_dataset_1, batch_size=1024, num_workers=0, shuffle=False)\n",
    "\n",
    "test_dataset_2 = h5_Dataset(features_h5_2)\n",
    "test_dataset_loader_2 = torch.utils.data.DataLoader(test_dataset_2, batch_size=1024, num_workers=0, shuffle=False)\n",
    "\n",
    "for m in tqdm(range(nr_models)):\n",
    "    \n",
    "    model = MULTI_BRANCH_TRANSFORMER_CLASSIFIER(DEVICE,\n",
    "                                                    conf_train_branch_1.emb_dim,\n",
    "                                                    conf_train_branch_2.emb_dim,\n",
    "                                                    conf_train_branch_1.num_heads,\n",
    "                                                    conf_train_branch_2.num_heads, \n",
    "                                                    conf_train_branch_1.num_encoder_layers,\n",
    "                                                    conf_train_branch_2.num_encoder_layers,\n",
    "                                                    conf_train_branch_1.dim_feedforward,\n",
    "                                                    conf_train_branch_2.dim_feedforward,\n",
    "                                                    conf_train_branch_1.dropout,\n",
    "                                                    conf_train_branch_2.dropout,\n",
    "                                                    conf_train_branch_1.num_classes).to(DEVICE)\n",
    "    \n",
    "    best_model_path = best_models_on_selected_metric[m] # path of the m th best model\n",
    "    model_state_dict = torch.load(best_model_path, map_location=torch.device(DEVICE)) # load\n",
    "\n",
    "    model.load_state_dict(model_state_dict) # load weights\n",
    "    model.eval() # set to eval mode ! \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    preds_all, labels_all = pred_with_one_model(model, test_dataset_loader_1, test_dataset_loader_2)\n",
    "    \n",
    "    preds_ensemble_local_test[m] = preds_all\n",
    "    labels_ensmble_local_test[m] = labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5840bd8-5b3b-4bc2-9ce2-2a7b3b259256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_ensemble_local_test.shape, labels_ensmble_local_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9929b-50d9-44b5-aa96-0970a88a5278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f'preds_100ensemble_transformer_cls_on_embeddings_bag_dinov2-vit-large_and_uni_run_1_10fold_local_test.npy', preds_ensemble_local_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd48ca-ce59-45df-92e2-a8451a0b2390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2e18ba9-3fda-4e0f-9d1b-17eb19c6caee",
   "metadata": {},
   "source": [
    "\n",
    "#### Simple mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f0e6f-a959-411c-a5a0-74aa4671f486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_pred_ensemble_local_test = np.mean(preds_ensemble_local_test, axis=0)\n",
    "final_pred_ensemble_local_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e360a0-dc33-4c16-a1ea-4512133a2b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_pred_ensemble_local_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37365623-0eb6-495f-9935-568d812aa8f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(np.argmax(final_pred_ensemble_local_test,1) > 0).sum() / final_pred_ensemble_local_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46f6ac-a119-4656-84e5-c544e3475695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc = plot_roc( tb_df_local_test.tb_positive.values, final_pred_ensemble_local_test  )\n",
    "print( np.mean(auc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368a632-31ef-4f0b-9149-08db72d0bdb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_pr(y_true, y_pred):\n",
    "    if y_pred.shape != y_true.shape:\n",
    "        # try to one-hot encode y_true\n",
    "        y_true = F.one_hot(torch.from_numpy(y_true).to(torch.int64), 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    auc_all = []\n",
    " \n",
    "    fpr, tpr, _ = precision_recall_curve(y_true[:, 1], y_pred[:, 1])\n",
    "    auc = average_precision_score(y_true[:, 1], y_pred[:, 1])\n",
    "    auc_all.append(auc)\n",
    "    plt.plot(fpr, tpr, '-', label='AUC : %.3f, label : %d' % (auc, 1))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971f41b-d087-4754-871e-cfd689dcd66f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_auc = plot_pr( tb_df_local_test.tb_positive.values, final_pred_ensemble_local_test  )\n",
    "print( np.mean(pr_auc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b315fd1-23f3-49f6-9232-7ceb24ce43ca",
   "metadata": {},
   "source": [
    "## Holdout set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37e838-f4a9-4843-9c91-34ce101f1ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class h5_Dataset_holdout(Dataset):\n",
    "    def __init__(self, emb_file_in_memory, transform=None):\n",
    "        self.transform = transform\n",
    "        self.emb_file_in_memory = emb_file_in_memory\n",
    "          \n",
    "    def __len__(self):\n",
    "        return self.emb_file_in_memory.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_data = self.emb_file_in_memory[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        \n",
    "        return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23447754-1b1a-421d-8310-96eee6d8afd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOAD MERGED H5 HOLDOUT IN MEMORY\n",
    "\n",
    "print(\"Loading merged h5 holdout file into memory - branch 1...\")\n",
    "coords_h5_holdout_1, features_h5_holdout_1, tb_positive_h5_holdout_1 = load_merged_h5_file(conf_preproc_branch_1[\"emb_h5_holdout\"])\n",
    "print(\"Done!\")\n",
    "print(features_h5_holdout_1.shape)\n",
    "\n",
    "print(\"Loading merged h5 holdout file into memory - branch 2...\")\n",
    "coords_h5_holdout_2, features_h5_holdout_2, tb_positive_h5_holdout_2 = load_merged_h5_file(conf_preproc_branch_2[\"emb_h5_holdout\"])\n",
    "print(\"Done!\")\n",
    "print(features_h5_holdout_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fc210-a078-4b1b-83bc-bcc9e98a4d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_bag_input_path_holdout = conf_preproc_branch_1[\"emb_dir_holdout\"]\n",
    "\n",
    "tb_df_holdout = pd.read_csv(conf_preproc_branch_1[\"tb_labels_csv_holdout\"])\n",
    "embeddings_bag_input_files_holdout = np.array( [ embeddings_bag_input_path_holdout + os.path.basename(i).replace(\".jpg\", \".h5\") for i in tb_df_holdout.file_path.values ] )\n",
    "\n",
    "embeddings_bag_input_files_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aeea4e-3b78-41c0-a770-46d10b75d4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tb_df_holdout[\"file_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76ce6b-a334-4ddd-b6a3-42a3dc75eb7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_bag_input_files_holdout[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37cc74-23e7-415b-a50b-4f6e39c39976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_models = best_models_on_selected_metric.shape[0]\n",
    "\n",
    "preds_ensemble_local_test = np.zeros((best_models_on_selected_metric.shape[0], embeddings_bag_input_files_holdout.shape[0], 2))\n",
    "labels_ensmble_local_test = np.zeros((best_models_on_selected_metric.shape[0], embeddings_bag_input_files_holdout.shape[0], 1))\n",
    "\n",
    "\n",
    "# DEFINE DATALOADERS\n",
    "holdout_dataset_1 = h5_Dataset_holdout(features_h5_holdout_1)\n",
    "holdout_dataset_loader_1 = torch.utils.data.DataLoader(holdout_dataset_1, batch_size=1024, num_workers=0, shuffle=False)\n",
    "\n",
    "holdout_dataset_2 = h5_Dataset_holdout(features_h5_holdout_2)\n",
    "holdout_dataset_loader_2 = torch.utils.data.DataLoader(holdout_dataset_2, batch_size=1024, num_workers=0, shuffle=False)\n",
    "\n",
    "for m in tqdm(range(nr_models)):\n",
    "    \n",
    "    model = MULTI_BRANCH_TRANSFORMER_CLASSIFIER(DEVICE,\n",
    "                                                    conf_train_branch_1.emb_dim,\n",
    "                                                    conf_train_branch_2.emb_dim,\n",
    "                                                    conf_train_branch_1.num_heads,\n",
    "                                                    conf_train_branch_2.num_heads, \n",
    "                                                    conf_train_branch_1.num_encoder_layers,\n",
    "                                                    conf_train_branch_2.num_encoder_layers,\n",
    "                                                    conf_train_branch_1.dim_feedforward,\n",
    "                                                    conf_train_branch_2.dim_feedforward,\n",
    "                                                    conf_train_branch_1.dropout,\n",
    "                                                    conf_train_branch_2.dropout,\n",
    "                                                    conf_train_branch_1.num_classes).to(DEVICE)\n",
    "    \n",
    "    \n",
    "    best_model_path = best_models_on_selected_metric[m] # path of the m th best model\n",
    "    model_state_dict = torch.load(best_model_path, map_location=torch.device(DEVICE)) # load\n",
    "\n",
    "    model.load_state_dict(model_state_dict) # load weights\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    preds_all, labels_all = pred_with_one_model(model, holdout_dataset_loader_1, holdout_dataset_loader_2)\n",
    "    \n",
    "    preds_ensemble_local_test[m] = preds_all\n",
    "    labels_ensmble_local_test[m] = labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4590c9-747a-4f1b-9a01-df48e549f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88e0f1-b3ae-4ebe-a7fc-56e0f9ebae45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f'preds_100ensemble_transformer_cls_on_embeddings_bag_dinov2-vit-large_and_uni_run_1_10fold_holdout.npy', preds_ensemble_local_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800b7cd-be3c-496b-8f6f-3dc8fc3c1f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_pred_ensemble_local_test = np.mean(preds_ensemble_local_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c46c6b-adc6-4be0-82a4-557f97e9fc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_df = tb_df_holdout[[\"image_id\"]].copy()\n",
    "prediction_df[\"prob\"] = final_pred_ensemble_local_test[:,1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "336754bf-e0d7-4659-9413-6546012784f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "filepath = \"/home/ngsci/project/tuberculosis_detection/submissions/submission_21_preds_100ensemble_transformer_cls_uni_run_2_10_fold_rocauc_0.9956_prauc_0.9487.csv\"\n",
    "prediction_df.to_csv(filepath, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2a761-63da-4865-905e-577732d556da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(final_pred_ensemble_local_test, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c24cbf-7492-4948-b568-a232c6638244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(final_pred_ensemble_local_test, axis=1).sum() / final_pred_ensemble_local_test.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
