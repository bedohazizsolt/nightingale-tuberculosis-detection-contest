{
 "cells": [
  {
   "cell_type": "raw",
   "id": "77f82339-baf2-44e2-b722-532e01136465",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install hydra-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46db1e-b647-45bd-a04c-c01a3b3ec209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import auc as calc_auc, precision_recall_curve, average_precision_score\n",
    "import random\n",
    "import glob\n",
    "import ngsci\n",
    "import hydra\n",
    "import h5py\n",
    "sys.path.append(\"../../../03_training/transformer_on_embeddings_bag/\")\n",
    "from transformer_model_cls import ClsTokenTransformerClassifier\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from omegaconf import DictConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34581f7-47db-4c86-ab61-a2be353af0b5",
   "metadata": {},
   "source": [
    "## LOAD CORRESPONDING SAVED CONFIG FILE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1baf17d-f90b-41bf-909d-ef6ab8bd152d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_preproc = OmegaConf.load(\"/home/ngsci/project/tuberculosis_detection/conf/preproc.yaml\")\n",
    "conf_train = OmegaConf.load(\"/home/ngsci/project/tuberculosis_detection/03_training/transformer_on_embeddings_bag/uni_224_224_patches_cls/runs/run_4_sqrt_sampling/conf_train.yaml\")\n",
    "conf_preproc = conf_preproc[\"transformer_on_embeddings_bag\"][\"uni_224_224_patches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1be0f-bfce-4106-8fee-1925705ee1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda:0' \n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14017e8-372f-4c66-8dc5-8ba4c0fe72f6",
   "metadata": {},
   "source": [
    "## Load models from CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9467adb-b266-4500-a361-78f8a3704871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = conf_train.results_dir\n",
    "results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff6eb0-8524-4af7-a5fb-35017520272b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoints_dir_cv_0 = f'{results_dir}cv_0/'\n",
    "checkpoints_dir_cv_1 = f'{results_dir}cv_1/'\n",
    "checkpoints_dir_cv_2 = f'{results_dir}cv_2/'\n",
    "checkpoints_dir_cv_3 = f'{results_dir}cv_3/'\n",
    "checkpoints_dir_cv_4 = f'{results_dir}cv_4/'\n",
    "checkpoints_dir_cv_5 = f'{results_dir}cv_5/'\n",
    "checkpoints_dir_cv_6 = f'{results_dir}cv_6/'\n",
    "checkpoints_dir_cv_7 = f'{results_dir}cv_7/'\n",
    "checkpoints_dir_cv_8 = f'{results_dir}cv_8/'\n",
    "checkpoints_dir_cv_9 = f'{results_dir}cv_9/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac6753-9946-4a9b-86af-a1dcbe8dab8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_names_all_cv = np.array([ np.array( sorted(  glob.glob( os.path.join(eval(f\"checkpoints_dir_cv_{i}\"), \"*.pt\"))   )) for i in range(10) ], dtype=object)\n",
    "file_names_all_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052cd3bb-36c8-4b83-b1f2-73ca6172aa55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_names_all_cv[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab60867-5ee7-416b-a131-9ce3aee4e510",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d04e15-b048-4cd2-a6ec-19d1618b92e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_bag_input_path = conf_preproc.emb_dir\n",
    "\n",
    "tb_df_local_test = pd.read_csv(conf_preproc[\"cv_split_dir\"] +'test_split_stratified.csv')\n",
    "tb_df_local_test.sort_values('image', inplace=True)\n",
    "embeddings_bag_input_files_local_test = np.array( sorted([ embeddings_bag_input_path + os.path.basename(i).replace(\".jpg\", \".h5\") for i in tb_df_local_test.file_path.values ]) )\n",
    "\n",
    "embeddings_bag_input_files_local_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7badd80-64c4-4a25-966a-b7c0fa614766",
   "metadata": {},
   "source": [
    "## Look for best models based on AUC or VAL LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea2450-ca1f-4d5d-aa7e-06eedc0e4ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a744349-ac47-47b5-92c0-2d4b27ceb53f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_val_auc = []\n",
    "\n",
    "for i in range(file_names_all_cv.shape[0]):\n",
    "    select = 10\n",
    "    max_auc_sort_index = np.argsort([float(os.path.basename(item).split('_')[5]) for item in file_names_all_cv[i]])[::-1]\n",
    "    \n",
    "    for m in range(select):\n",
    "        max_auc_model = file_names_all_cv[i][max_auc_sort_index[m]]\n",
    "        best_models_on_val_auc.append(max_auc_model)\n",
    "\n",
    "best_models_on_val_auc = np.array(best_models_on_val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d73193-ad50-4306-8e1e-7ca56b8c0cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_val_auc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e51d5-2a43-453f-a4ea-609c51e2c233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_val_auc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5745d6-15eb-48d7-a244-79c911492de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"ROC AUC of selected models: \", np.mean([float(e.split('_auc_')[1].split('_')[0]) for e in best_models_on_val_auc]))\n",
    "print(\"PR AUC of selected models: \", np.mean([float(e.split('_prauc_')[1].split('_')[0]) for e in best_models_on_val_auc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921b5d37-2c60-4aa1-affe-8d108a14a4e5",
   "metadata": {},
   "source": [
    "#### PR AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7512e60-d2fc-4e4c-a502-ee40ed999548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_prauc = []\n",
    "\n",
    "for i in range(file_names_all_cv.shape[0]):\n",
    "    select = 10\n",
    "    max_prauc_sort_index = np.argsort([float(os.path.basename(item).split('_')[7]) for item in file_names_all_cv[i]])[::-1]\n",
    "    \n",
    "    for m in range(select):\n",
    "        max_prauc_model = file_names_all_cv[i][max_prauc_sort_index[m]]\n",
    "        best_models_on_prauc.append(max_prauc_model)\n",
    "\n",
    "best_models_on_prauc = np.array(best_models_on_prauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8f56d-a4b4-4e3a-8c93-ce9ed52e3554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_prauc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cd830-fbd3-41ea-8cf9-20933dd41863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_prauc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658de2f6-99a9-45f1-811c-2f234019d741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"ROC AUC of selected models: \", np.mean([float(e.split('_auc_')[1].split('_')[0]) for e in best_models_on_prauc]))\n",
    "print(\"PR AUC of selected models: \", np.mean([float(e.split('_prauc_')[1].split('_')[0]) for e in best_models_on_prauc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20638b68-1085-4c9a-83e3-7ed7a58062ff",
   "metadata": {},
   "source": [
    "## Predict with model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232e952-6aed-4df0-b6dd-39d432c126a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_roc(y_true, y_pred):\n",
    "    if y_pred.shape != y_true.shape:\n",
    "        y_true = F.one_hot(torch.from_numpy(y_true).to(torch.int64), 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    auc_all = []\n",
    "    for class_ind in range(y_pred.shape[-1]):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, class_ind], y_pred[:, class_ind])\n",
    "        auc = roc_auc_score(y_true[:, class_ind], y_pred[:, class_ind])\n",
    "        auc_all.append(auc)\n",
    "        plt.plot(fpr, tpr, '-', label='AUC : %.3f, label : %d' % (auc, class_ind))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1a435-ff64-4ad6-be27-13f4dc785270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_merged_h5_file(filename):\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        coords = f['coords'][()]\n",
    "        features = f['features'][()]\n",
    "        tb_positive = f['tb_positive'][()]\n",
    "        \n",
    "        return coords, features, tb_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50027b87-db87-4fe9-bb62-9ee2951c9c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class h5_Dataset(Dataset):\n",
    "    def __init__(self, emb_file_in_memory, cv_df, transform=None):\n",
    "        self.transform = transform\n",
    "        self.emb_file_in_memory = emb_file_in_memory\n",
    "        self.cv_df = cv_df\n",
    "        \n",
    "        self.cv_samples_index = np.array([ int(os.path.basename(f).replace(\".jpg\",\"\").replace(\"tb\",\"\"))-1 for f in self.cv_df[\"file_path\"] ])\n",
    "        self.cv_idx_to_all_idx = dict(zip(np.arange(self.cv_samples_index.shape[0]), self.cv_samples_index))                                 \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cv_samples_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        all_idx = self.cv_idx_to_all_idx[idx]\n",
    "        \n",
    "        image_data = self.emb_file_in_memory[all_idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        \n",
    "        return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b1ce4-9a19-4a97-ab8d-c6debbf60f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8baed7-d121-40ae-82a3-71e5b97d7644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_with_one_model(model, data_loader):\n",
    "    \n",
    "    preds_all = []\n",
    "    labels_all = []\n",
    "    \n",
    "    for data in data_loader:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            data = data.to(DEVICE, dtype=torch.float32, non_blocking=True)\n",
    "                                       \n",
    "            _, preds, label, _, _ = model(data)\n",
    "\n",
    "        preds_all.append(preds.cpu().detach().numpy()[:,:2])\n",
    "        labels_all.append(label.cpu().numpy())\n",
    "        \n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    labels_all = np.concatenate(labels_all)\n",
    "    \n",
    "    return preds_all, labels_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99f308-29de-492e-b663-ec55609db4f8",
   "metadata": {},
   "source": [
    "### Select best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78930f9d-5dd7-46ba-9d01-bd84ebe9925e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_selected_metric = best_models_on_prauc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5a896a7-f095-473c-bff0-f57c6782a848",
   "metadata": {
    "tags": []
   },
   "source": [
    "best_models_on_selected_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb3ec8-4d32-4339-a7f2-127e1aceefc4",
   "metadata": {},
   "source": [
    "### Local test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d943d-2c50-4d0b-9216-41d8a17a163b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOAD MERGED H5 IN MEMORY\n",
    "print(\"Loading merged h5 local test file into memory...\")\n",
    "coords_h5, features_h5, tb_positive_h5 = load_merged_h5_file(conf_preproc[\"emb_h5\"])\n",
    "\n",
    "print(\"\\nDone!\")\n",
    "print(features_h5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8bace-ab39-4ee6-bd02-7e7b079e2d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_models = best_models_on_selected_metric.shape[0]\n",
    "\n",
    "preds_ensemble_local_test = np.zeros((best_models_on_selected_metric.shape[0], embeddings_bag_input_files_local_test.shape[0], 2))\n",
    "labels_ensmble_local_test = np.zeros((best_models_on_selected_metric.shape[0], embeddings_bag_input_files_local_test.shape[0], 1))\n",
    "\n",
    "# DEFINE DATALOADER\n",
    "test_df = pd.read_csv(f'{conf_preproc[\"cv_split_dir_10fold\"]}test_split_stratified.csv')\n",
    "test_dataset = h5_Dataset(features_h5, test_df)\n",
    "test_dataset_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, num_workers=0, shuffle=False)\n",
    "\n",
    "for m in tqdm(range(nr_models)):\n",
    "    \n",
    "    model = ClsTokenTransformerClassifier(conf_train.emb_dim, \n",
    "                                      conf_train.num_heads, \n",
    "                                      conf_train.num_encoder_layers, \n",
    "                                      conf_train.dim_feedforward,\n",
    "                                      conf_train.dropout,\n",
    "                                      conf_train.num_classes).to(DEVICE)\n",
    "    \n",
    "    best_model_path = best_models_on_selected_metric[m] # path of the m th best model\n",
    "    model_state_dict = torch.load(best_model_path, map_location=torch.device(DEVICE)) # load\n",
    "\n",
    "    model.load_state_dict(model_state_dict) # load weights\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    preds_all, labels_all = pred_with_one_model(model, data_loader=test_dataset_loader)\n",
    "    \n",
    "    preds_ensemble_local_test[m] = preds_all\n",
    "    labels_ensmble_local_test[m] = labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5840bd8-5b3b-4bc2-9ce2-2a7b3b259256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_ensemble_local_test.shape, labels_ensmble_local_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb78e6-d47c-493a-b5d7-d3efa1d717fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f'preds_100ensemble_transformer_cls_on_embeddings_bag_uni_run_4_sqrt_sampling_10fold_local_test.npy', preds_ensemble_local_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e18ba9-3fda-4e0f-9d1b-17eb19c6caee",
   "metadata": {},
   "source": [
    "\n",
    "#### Simple mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f0e6f-a959-411c-a5a0-74aa4671f486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_pred_ensemble_local_test = np.mean(preds_ensemble_local_test, axis=0)\n",
    "final_pred_ensemble_local_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e360a0-dc33-4c16-a1ea-4512133a2b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_pred_ensemble_local_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37365623-0eb6-495f-9935-568d812aa8f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(np.argmax(final_pred_ensemble_local_test,1) > 0).sum() / final_pred_ensemble_local_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46f6ac-a119-4656-84e5-c544e3475695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc = plot_roc( tb_df_local_test.tb_positive.values, final_pred_ensemble_local_test  )\n",
    "print( np.mean(auc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368a632-31ef-4f0b-9149-08db72d0bdb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_pr(y_true, y_pred):\n",
    "    if y_pred.shape != y_true.shape:\n",
    "        # try to one-hot encode y_true\n",
    "        y_true = F.one_hot(torch.from_numpy(y_true).to(torch.int64), 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    auc_all = []\n",
    " \n",
    "    fpr, tpr, _ = precision_recall_curve(y_true[:, 1], y_pred[:, 1])\n",
    "    auc = average_precision_score(y_true[:, 1], y_pred[:, 1])\n",
    "    auc_all.append(auc)\n",
    "    plt.plot(fpr, tpr, '-', label='AUC : %.3f, label : %d' % (auc, 1))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971f41b-d087-4754-871e-cfd689dcd66f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_auc = plot_pr( tb_df_local_test.tb_positive.values, final_pred_ensemble_local_test  )\n",
    "print( np.mean(pr_auc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b315fd1-23f3-49f6-9232-7ceb24ce43ca",
   "metadata": {},
   "source": [
    "## Holdout set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37e838-f4a9-4843-9c91-34ce101f1ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class h5_Dataset_holdout(Dataset):\n",
    "    def __init__(self, emb_file_in_memory, transform=None):\n",
    "        self.transform = transform\n",
    "        self.emb_file_in_memory = emb_file_in_memory\n",
    "          \n",
    "    def __len__(self):\n",
    "        return self.emb_file_in_memory.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_data = self.emb_file_in_memory[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        \n",
    "        return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23447754-1b1a-421d-8310-96eee6d8afd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Loading merged h5 holdout file into memory...\")\n",
    "\n",
    "holdout_h5_file = \"/home/ngsci/project/tuberculosis_detection/02_patch_embeddings/uni_224_224_patches/patch_embeddings_uni_224_holdout.h5\"\n",
    "coords_h5_holdout, features_h5_holdout, tb_positive_h5_holdout = load_merged_h5_file(holdout_h5_file)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fc210-a078-4b1b-83bc-bcc9e98a4d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_bag_input_path_holdout = conf_preproc[\"emb_dir_holdout\"]\n",
    "\n",
    "tb_df_holdout = pd.read_csv(conf_preproc[\"tb_labels_csv_holdout\"])\n",
    "embeddings_bag_input_files_holdout = np.array( [ embeddings_bag_input_path_holdout + os.path.basename(i).replace(\".jpg\", \".h5\") for i in tb_df_holdout.file_path.values ] )\n",
    "\n",
    "embeddings_bag_input_files_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aeea4e-3b78-41c0-a770-46d10b75d4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tb_df_holdout[\"file_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76ce6b-a334-4ddd-b6a3-42a3dc75eb7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_bag_input_files_holdout[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37cc74-23e7-415b-a50b-4f6e39c39976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_models = best_models_on_selected_metric.shape[0]\n",
    "\n",
    "preds_ensemble_local_test = np.zeros((best_models_on_selected_metric.shape[0], embeddings_bag_input_files_holdout.shape[0], 2))\n",
    "labels_ensmble_local_test = np.zeros((best_models_on_selected_metric.shape[0], embeddings_bag_input_files_holdout.shape[0], 1))\n",
    "\n",
    "\n",
    "# DEFINE DATALOADER\n",
    "holdout_dataset = h5_Dataset_holdout(features_h5_holdout)\n",
    "holdout_dataset_loader = torch.utils.data.DataLoader(holdout_dataset, batch_size=1024, num_workers=0, shuffle=False)\n",
    "\n",
    "for m in tqdm(range(nr_models)):\n",
    "    \n",
    "    model = ClsTokenTransformerClassifier(conf_train.emb_dim, \n",
    "                                      conf_train.num_heads, \n",
    "                                      conf_train.num_encoder_layers, \n",
    "                                      conf_train.dim_feedforward,\n",
    "                                      conf_train.dropout,\n",
    "                                      conf_train.num_classes\n",
    "                                                 ).to(DEVICE)\n",
    "    \n",
    "    \n",
    "    best_model_path = best_models_on_selected_metric[m] # path of the m th best model\n",
    "    model_state_dict = torch.load(best_model_path, map_location=torch.device(DEVICE)) # load\n",
    "\n",
    "    model.load_state_dict(model_state_dict) # load weights\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    preds_all, labels_all = pred_with_one_model(model, data_loader=holdout_dataset_loader)\n",
    "    \n",
    "    preds_ensemble_local_test[m] = preds_all\n",
    "    labels_ensmble_local_test[m] = labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9305565-8788-421c-a28e-13a50cb54fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94028b50-83f6-4a29-9e1a-21d6f0f594d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f'preds_100ensemble_transformer_cls_on_embeddings_bag_uni_run_4_sqrt_sampling_10fold_holdout.npy', preds_ensemble_local_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800b7cd-be3c-496b-8f6f-3dc8fc3c1f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_pred_ensemble_local_test = np.mean(preds_ensemble_local_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c46c6b-adc6-4be0-82a4-557f97e9fc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_df = tb_df_holdout[[\"image_id\"]].copy()\n",
    "prediction_df[\"prob\"] = final_pred_ensemble_local_test[:,1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "336754bf-e0d7-4659-9413-6546012784f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "filepath = \"/home/ngsci/project/tuberculosis_detection/submissions/submission_21_preds_100ensemble_transformer_cls_uni_run_2_10_fold_rocauc_0.9956_prauc_0.9487.csv\"\n",
    "prediction_df.to_csv(filepath, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2a761-63da-4865-905e-577732d556da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(final_pred_ensemble_local_test, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c24cbf-7492-4948-b568-a232c6638244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(final_pred_ensemble_local_test, axis=1).sum() / final_pred_ensemble_local_test.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
